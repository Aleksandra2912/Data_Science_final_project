{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13308296-52b9-4cfc-a625-2598f03a4ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, VarianceThreshold, RFE, RFECV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, brier_score_loss, \n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from IPython.display import display\n",
    "\n",
    "# Pandas configuration \n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# To plot pretty figures \n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=10)\n",
    "mpl.rc('ytick', labelsize=10)\n",
    "\n",
    "### Create a folder and define the save_fig() function which is used through \n",
    "### this notebook to save the figures in hig-res ####\n",
    "\n",
    "PROJECT_ROOT_DIR = r\"C:\\Users\\aleks\\OneDrive - Coventry University\\Desktop\\Project_Data\"\n",
    "CHAPTER_ID = \"project_figures\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af78d75e-8af5-4afb-88f6-b52e56d378b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = joblib.load('X_train_final_MI.joblib')\n",
    "y_train_final = joblib.load('y_train_final_MI.joblib')\n",
    "X_test_final = joblib.load('X_test_final_MI.joblib')\n",
    "y_test_final = joblib.load('y_test_final_MI.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f337f9a-6cad-45a4-bf94-173492bc7c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20409, 20)\n",
      "(5103, 20)\n",
      "(20409,)\n",
      "(5103,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_final.shape)\n",
    "print(X_test_final.shape)\n",
    "print(y_train_final.shape)\n",
    "print(y_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "315b2ea8-7611-4a63-a522-098354f48daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation: Logistic Regression\n",
      "Cross validation: Random Forest\n",
      "Cross validation: AdaBoost\n",
      "Cross validation: MLP\n",
      "Cross validation: XGBoost\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, \n",
    "                                              class_weight='balanced',\n",
    "                                              random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42,\n",
    "                                           class_weight='balanced'),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"MLP\": MLPClassifier(max_iter=1000, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Cross validation: {name}\")\n",
    "    aucs, f1s, precisions, recalls, briers, accuracies = [], [], [], [], [], []\n",
    "    \n",
    "    for train_idx, val_idx in cv.split(X_train_final, y_train_final):\n",
    "        # Split the training fold\n",
    "        X_tr, X_val = X_train_final.iloc[train_idx], X_train_final.iloc[val_idx]\n",
    "        y_tr, y_val = y_train_final.iloc[train_idx], y_train_final.iloc[val_idx]\n",
    "        \n",
    "        # Apply SMOTE only to training fold (not validation)\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_tr_resampled, y_tr_resampled = smote.fit_resample(X_tr, y_tr)\n",
    "        \n",
    "        # Train on resampled training data, validate on original validation data\n",
    "        model.fit(X_tr_resampled, y_tr_resampled)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        aucs.append(roc_auc_score(y_val, y_proba))\n",
    "        f1s.append(f1_score(y_val, y_pred))\n",
    "        precisions.append(precision_score(y_val, y_pred))\n",
    "        recalls.append(recall_score(y_val, y_pred))\n",
    "        accuracies.append(accuracy_score(y_val, y_pred))\n",
    "        briers.append(brier_score_loss(y_val, y_proba))\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"AUC Mean\": np.mean(aucs),\n",
    "        \"F1 Mean\": np.mean(f1s),\n",
    "        \"Precision Mean\": np.mean(precisions),\n",
    "        \"Recall Mean\": np.mean(recalls),\n",
    "        \"Accuracy Mean\": np.mean(accuracies),\n",
    "        \"Brier Score Mean\": np.mean(briers),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c322bb-956a-4510-85ab-49befa071d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  AUC Mean   F1 Mean  Precision Mean  Recall Mean  \\\n",
      "0  Logistic Regression  0.812711  0.541487        0.445465     0.690531   \n",
      "1        Random Forest  0.816701  0.503982        0.622524     0.423881   \n",
      "2             AdaBoost  0.820071  0.558803        0.500375     0.633674   \n",
      "3                  MLP  0.769147  0.495754        0.413938     0.618462   \n",
      "4              XGBoost  0.810597  0.485523        0.613798     0.401996   \n",
      "\n",
      "   Accuracy Mean  Brier Score Mean  \n",
      "0       0.759076          0.166199  \n",
      "1       0.828311          0.125295  \n",
      "2       0.793866          0.205761  \n",
      "3       0.740947          0.179477  \n",
      "4       0.824587          0.127050  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "results_df.to_csv(r\"C:\\Users\\aleks\\OneDrive - Coventry University\\Desktop\\Project_Data\\'model_cv_results_SMOTE.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
